{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunacpg/MVP-Machine-Learning/blob/main/MVP_Ci%C3%AAncia_de_dados_e_Analytcs_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W0fs-MY_Zk9"
      },
      "source": [
        "# MVP - Análise de Sentimentos e Extração de Tópicos das Avaliações da Amazon\n",
        "\n",
        "## 1. Definição do Problema\n",
        "\n",
        "### 1.1 Objetivo\n",
        "O objetivo deste projeto é aplicar técnicas de **Processamento de Linguagem Natural (NLP)** para analisar as avaliações dos consumidores da Amazon. As análises incluem:\n",
        "\n",
        "- **Análise de Sentimentos**: Identificar a polaridade das avaliações (positiva, neutra ou negativa).\n",
        "- **Extração de Tópicos**: Descobrir os principais temas abordados nas avaliações (ex.: qualidade, preço, entrega).\n",
        "\n",
        "Esses insights poderão ser usados para:\n",
        "- Melhorar a experiência do cliente.\n",
        "- Oferecer feedback direto para aprimorar produtos e serviços.\n",
        "\n",
        "**Métricas de sucesso sugeridas**:\n",
        "1. **Análise de Sentimentos**: Obter pelo menos 85% de precisão na classificação.\n",
        "2. **Extração de Tópicos**: Identificar ao menos 3 tópicos principais com uma relevância acima de 70%.\n",
        "\n",
        "---\n",
        "\n",
        "### 1.2 Descrição do Problema\n",
        "Os consumidores frequentemente compartilham opiniões detalhadas em avaliações na Amazon, mas essas informações são não estruturadas e difíceis de analisar em escala. Usaremos técnicas de NLP para responder a perguntas como:\n",
        "- Quais fatores levam à satisfação ou insatisfação dos clientes?\n",
        "- Quais palavras-chave são mais comuns em avaliações positivas e negativas?\n",
        "- Como as avaliações se correlacionam com a pontuação geral dos produtos?\n",
        "\n",
        "---\n",
        "\n",
        "### 1.3 Premissas e Hipóteses\n",
        "\n",
        "**Premissas**:\n",
        "1. Avaliações com pontuação alta (4 ou 5) representam satisfação, enquanto pontuações baixas (1 ou 2) indicam insatisfação.\n",
        "2. Textos das avaliações contêm informações valiosas sobre aspectos específicos dos produtos.\n",
        "\n",
        "**Hipóteses**:\n",
        "1. Palavras relacionadas a \"qualidade\", \"preço\" e \"funcionalidade\" aparecem frequentemente em avaliações positivas.\n",
        "2. Problemas de \"durabilidade\" ou \"descrições enganosas\" são recorrentes em avaliações negativas.\n",
        "\n",
        "**Validação das Hipóteses**:\n",
        "- Realizaremos uma análise de frequência de palavras em cada categoria de sentimento.\n",
        "- Compararemos os tópicos extraídos com as hipóteses iniciais.\n",
        "\n",
        "---\n",
        "\n",
        "### 1.4 Restrições e Condições\n",
        "\n",
        "- **Tamanho do Dataset**: Contém 28.423 avaliações, sendo necessário considerar estratégias de amostragem.\n",
        "- **Recursos Computacionais**: Modelos NLP podem ser computacionalmente caros. Priorizaremos eficiência com técnicas como:\n",
        "  - **TF-IDF** para vetorização de texto.\n",
        "  - **Modelos pré-treinados** para reduzir o custo computacional.\n",
        "  - **Amostragem** para trabalhar com dados menores durante a prototipação.\n",
        "\n",
        "---\n",
        "\n",
        "### Conclusão da Estrutura\n",
        "Essa estrutura segue corretamente o objetivo de um MVP para análise de sentimentos e extração de tópicos com NLP.\n",
        "- Está alinhada com os requisitos de um projeto acadêmico ou prático.\n",
        "- Permite aprofundar nas etapas de análise e validação com modelos.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bloco 1: Importação de Bibliotecas**\n",
        "\n",
        "Explicação: Neste bloco, importamos todas as bibliotecas necessárias para o projeto, incluindo:\n",
        "\n",
        "Manipulação e análise de dados (pandas, numpy).\n",
        "Processamento de texto (tensorflow.keras, sklearn).\n",
        "Visualização de dados (matplotlib)."
      ],
      "metadata": {
        "id": "ariA5JoH_Pkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação de bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5LzMUf80_l2x"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bloco 2: Carregar e Preparar os Dados**\n",
        "\n",
        "Explicação:\n",
        "\n",
        "Carregamos o dataset e realizamos o pré-processamento:\n",
        "Filtramos as colunas relevantes (Score e Text).\n",
        "Removemos valores nulos e duplicados.\n",
        "Excluímos avaliações neutras (Score == 3).\n",
        "Mapeamos as pontuações para rótulos binários: 0 (negativo) e 1 (positivo).\n",
        "Exibimos a distribuição dos sentimentos."
      ],
      "metadata": {
        "id": "IQ_Qox_P_pIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Carregar e preparar os dados\n",
        "df = pd.read_csv('amostra.csv')\n",
        "\n",
        "# Contar as linhas antes do tratamento\n",
        "initial_count = len(df)\n",
        "\n",
        "# Filtrar colunas relevantes\n",
        "df = df[['Score', 'Text']]\n",
        "\n",
        "# Remover valores nulos e duplicados\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Contar as linhas após o tratamento\n",
        "final_count = len(df)\n",
        "print(f\"Linhas removidas: {initial_count - final_count}\")\n",
        "print(f\"Linhas restantes: {final_count}\")\n",
        "\n",
        "# Excluir avaliações neutras\n",
        "df = df[df['Score'] != 3]\n",
        "\n",
        "# Mapear Score para Sentimento (0: Negativo, 1: Positivo)\n",
        "df['Sentiment'] = df['Score'].map({1: 0, 2: 0, 4: 1, 5: 1})\n",
        "\n",
        "# Exibir a distribuição de sentimentos\n",
        "print(\"Distribuição dos Sentimentos:\")\n",
        "print(df['Sentiment'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QewbsEZ_tt7",
        "outputId": "60b9fcc5-e414-478b-9857-44a6f5bde95f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linhas removidas: 1309\n",
            "Linhas restantes: 27114\n",
            "Distribuição dos Sentimentos:\n",
            "Sentiment\n",
            "1    21233\n",
            "0     3862\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-79-5c20a615e376>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Sentiment'] = df['Score'].map({1: 0, 2: 0, 4: 1, 5: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bloco 3: Tokenização e Padronização do Texto**\n",
        "\n",
        "Explicação:\n",
        "\n",
        "Usamos o Tokenizer para transformar os textos em sequências numéricas.\n",
        "Aplicamos padding para uniformizar o comprimento das sequências.\n",
        "Exibimos os formatos finais dos tensores de entrada (X_padded) e dos rótulos (y).\n",
        "\n"
      ],
      "metadata": {
        "id": "OkEvHgzT_wBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Configuração do Tokenizer\n",
        "max_words = 10000  # Tamanho do vocabulário\n",
        "max_len = 100  # Comprimento máximo das sequências\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['Text'])\n",
        "\n",
        "# Converter textos em sequências\n",
        "X_seq = tokenizer.texts_to_sequences(df['Text'])\n",
        "\n",
        "# Aplicar padding nas sequências\n",
        "X_padded = pad_sequences(X_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Definir rótulos\n",
        "y = df['Sentiment'].values\n",
        "\n",
        "# Verificar o formato das sequências e rótulos\n",
        "print(f\"Formato de X_padded: {X_padded.shape}\")\n",
        "print(f\"Formato de y: {y.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgAq1ohd_18J",
        "outputId": "36f3a829-7048-4bec-906b-d3e2627e45bc"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato de X_padded: (25095, 100)\n",
            "Formato de y: (25095,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bloco 4: Divisão dos Dados**\n",
        "\n",
        "Explicação:\n",
        "\n",
        "Dividimos os dados entre treino e teste (80/20) para avaliar o desempenho do modelo."
      ],
      "metadata": {
        "id": "pDmssLiM_5bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão dos dados entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Exibir tamanhos dos conjuntos\n",
        "print(f\"Tamanho do conjunto de treino: {X_train.shape}\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkSj15o6_-Nh",
        "outputId": "b43aa30e-fd97-4e1e-b840-6cd04798a6dc"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: (20076, 100)\n",
            "Tamanho do conjunto de teste: (5019, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bloco 4.1: Faz Sentido Utilizar Validação Cruzada?**\n",
        "\n",
        "Explicação:\n",
        "\n",
        "Validação cruzada (K-Fold) faz sentido em muitos problemas, mas no caso de modelos de Deep Learning, geralmente não é usada diretamente porque:\n",
        "O treinamento é computacionalmente caro e a validação cruzada multiplicaria o custo.\n",
        "1. Deep Learning é computacionalmente caro e validação cruzada não é prática.\n",
        "2. Usaremos validation_split no treinamento para simular validação cruzada de forma eficiente.\n"
      ],
      "metadata": {
        "id": "FNs8pM6yC2qc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bloco 5: Construção e Compilação do Modelo**\n",
        "\n",
        "Explicação:\n",
        "\n",
        "Criamos o modelo LSTM:\n",
        "\n",
        "1.   Embedding: Representação densa das palavras.\n",
        "2.  LSTM: Captura o contexto sequencial.\n",
        "3.  Dense: Camada de saída binária\n",
        "\n",
        "Compilamos o modelo usando:\n",
        "\n",
        "1. Adam: Otimizador eficiente.\n",
        "2. Binary Crossentropy: Função de perda para classificação binária."
      ],
      "metadata": {
        "id": "gFWfdDtJIvSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Construção do modelo LSTM\n",
        "embedding_dim = 128  # Dimensão dos embeddings\n",
        "lstm_units = 64  # Unidades na camada LSTM\n",
        "\n",
        "# Construção do modelo\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=embedding_dim),  # Camada de embeddings\n",
        "    LSTM(lstm_units, return_sequences=False),  # Camada LSTM\n",
        "    Dense(1, activation='sigmoid')  # Camada de saída para classificação binária\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Forçar a construção do modelo para definir as dimensões de entrada\n",
        "model.build(input_shape=(None, max_len))  # None é o batch size, max_len é o comprimento das sequências\n",
        "\n",
        "# Exibir o resumo do modelo\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "LfaLLHf1G9Az",
        "outputId": "4ea171b1-b44f-4d0f-8fe5-943d79763821"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_10 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m1,280,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m49,408\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,329,473\u001b[0m (5.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,329,473</span> (5.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,329,473\u001b[0m (5.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,329,473</span> (5.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bloco 6: Treinamento do Modelo**\n",
        "\n",
        "Explicação:\n",
        "\n",
        "Treinamos o modelo por 5 épocas, usando 20% dos dados de treino como conjunto de validação."
      ],
      "metadata": {
        "id": "xG9g02bzI0ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Treinamento com validation_split\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2  # 20% dos dados de treino são usados para validação\n",
        ")\n",
        "\n",
        "# Exibir os dados de validação durante o treinamento\n",
        "print(\"Histórico do Treinamento com Validação:\")\n",
        "print(history.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es_qKGsGG_78",
        "outputId": "a219311e-dba9-4a81-be7f-15f65566d3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 109ms/step - accuracy: 0.8386 - loss: 0.4448 - val_accuracy: 0.8404 - val_loss: 0.4362\n",
            "Epoch 2/5\n",
            "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 91ms/step - accuracy: 0.8552 - loss: 0.4034 - val_accuracy: 0.8404 - val_loss: 0.4299\n",
            "Epoch 3/5\n",
            "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 130ms/step - accuracy: 0.8621 - loss: 0.3671 - val_accuracy: 0.8755 - val_loss: 0.3044\n",
            "Epoch 4/5\n",
            "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 122ms/step - accuracy: 0.9296 - loss: 0.1977 - val_accuracy: 0.9034 - val_loss: 0.2548\n",
            "Epoch 5/5\n",
            "\u001b[1m502/502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 89ms/step - accuracy: 0.9581 - loss: 0.1221 - val_accuracy: 0.9011 - val_loss: 0.2626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Salvar o histórico do treinamento em CSV\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.to_csv('historico_treinamento.csv', index=False)\n",
        "\n",
        "print(\"Histórico do treinamento salvo como 'historico_treinamento.csv'.\")\n"
      ],
      "metadata": {
        "id": "ApyqXPmCJ-OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bloco 7: Avaliação do Modelo no Conjunto de Teste**\n",
        "\n",
        "Explicação:\n",
        "\n",
        "Avaliamos o desempenho no conjunto de teste para calcular a perda e a acurácia final."
      ],
      "metadata": {
        "id": "YZZGeD54I4tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Avaliação do modelo no conjunto de teste\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Exibir a acurácia no conjunto de teste\n",
        "print(f\"Acurácia no conjunto de teste: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "9Www1JA3HBbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bloco 8: Relatório de Classificação e Matriz de Confusão**\n",
        "\n",
        "Explicação:\n",
        "\n",
        "Geramos um relatório de classificação para verificar métricas detalhadas (precisão, recall, F1-score).\n",
        "Exibimos uma matriz de confusão para visualizar o desempenho."
      ],
      "metadata": {
        "id": "4aL_pIQQI8Yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Relatório de classificação e matriz de confusão\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Relatório de classificação\n",
        "print(\"Relatório de Classificação:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "KZLYhbkHHCWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bloco 9: Visualização das Curvas de Treinamento**\n",
        "\n",
        "Explicação:\n",
        "\n",
        "Plotamos as curvas de acurácia e perda para identificar sinais de underfitting ou overfitting."
      ],
      "metadata": {
        "id": "XHE_IV7aJB-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar a acurácia\n",
        "plt.plot(history.history['accuracy'], label='Treino')\n",
        "plt.plot(history.history['val_accuracy'], label='Validação')\n",
        "plt.title('Acurácia ao Longo das Épocas')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotar a perda\n",
        "plt.plot(history.history['loss'], label='Treino')\n",
        "plt.plot(history.history['val_loss'], label='Validação')\n",
        "plt.title('Perda ao Longo das Épocas')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Perda')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bhNoizVwJFPr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgdHyQYfVIs5wFCkBqJLC7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}